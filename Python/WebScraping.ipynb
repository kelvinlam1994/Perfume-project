{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HKTVMALL \n",
    "import datetime\n",
    "import math\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "# 初始化 WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 瀏覽到目標頁面\n",
    "driver.get(\"https://www.hktvmall.com/hktv/zh/search_a?keyword=%E9%A6%99%E6%B0%B4&page=0\")\n",
    "\n",
    "# 初始化 WebDriverWait\n",
    "wait = WebDriverWait(driver, 5)\n",
    "\n",
    "# 定義一個變量來跟踪產品索引\n",
    "index = 1\n",
    "\n",
    "# how many total page count , a count to help stop loop in the last page\n",
    "Total_Page_element = WebDriverWait(driver, 5).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//*[@id=\"search-result-wrapper\"]/div/div[3]/div[3]/div/span'))\n",
    ").text\n",
    "page_TOP_num = int(re.search(r'\\d+', Total_Page_element).group())\n",
    "\n",
    "print (page_TOP_num )\n",
    "\n",
    "# 定義一個變量來跟踪當前頁數\n",
    "web_page_count = 1\n",
    "\n",
    "# 創建一個空的 DataFrame\n",
    "columns = [\"Title\", \"Price\", \"Rate\"]\n",
    "data = pd.DataFrame(columns=columns)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print(f\"正在處理第 {web_page_count} 頁\")\n",
    "        # roll to the bottom to load full page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # 循環處理當前頁面的所有產品\n",
    "        while True:\n",
    "            try:\n",
    "                # 動態生成 XPath 表達式\n",
    "                open_page_btn = driver.find_element(By.XPATH, f'//*[@id=\"algolia-search-result-container\"]/div/div/span[{index}]')\n",
    "                open_page_btn.click()\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "                \n",
    "                time.sleep(2)\n",
    "                #close add\n",
    "                try:\n",
    "                    click_add = driver.find_element(By.XPATH,'/html/body/div[2]/div[6]/div/i')\n",
    "                    click_add.click()\n",
    "                except:\n",
    "                    pass\n",
    "                # 在產品頁面上提取數據\n",
    "                try:\n",
    "                    title = driver.find_element(By.XPATH, '//*[@id=\"breadcrumb\"]/div[2]/ul/li[2]/h1').text\n",
    "                except:\n",
    "                    title = \"N/A\"\n",
    "                try:\n",
    "                    #find_brand Name\n",
    "                    product_name = driver.find_elements(By.XPATH, '//*[@id=\"breadcrumb\"]/div[2]/ul/li[2]/h1')[0].text\n",
    "                    brand_name = product_name.split(\" - \")[0]\n",
    "                except:\n",
    "                    brand_name = 'N/A'\n",
    "                try:\n",
    "                    price_text = driver.find_element(By.CLASS_NAME, 'price').text\n",
    "                    price = price_text.split('\\n')[0].strip('$')\n",
    "                except:\n",
    "                    price = \"N/A\"\n",
    "                try:\n",
    "                    rate = driver.find_element(By.CLASS_NAME, 'averageRating').text\n",
    "                except:\n",
    "                    rate = \"N/A\"\n",
    "                # try:\n",
    "                #     short_desc = driver.find_element(By.XPATH, \"//span[contains(@class = 'short-desc')]\").text\n",
    "                # except:\n",
    "                #     short_desc = \"N/A\"\n",
    "                try:\n",
    "                    origin = driver.find_elements(By.CLASS_NAME, 'productPackingSpec')[0].text\n",
    "                    if '包裝' in origin:\n",
    "                        origin = driver.find_elements(By.CLASS_NAME, 'productPackingSpec')[1].text\n",
    "                    origin = origin.split(' ')[1]   \n",
    "                except:\n",
    "                    origin = \"N/A\"\n",
    "                try: \n",
    "                    #open the graph and open 365 days\n",
    "                    wait = WebDriverWait(driver, 1)\n",
    "                    click_date = driver.find_element(By.XPATH, '//*[@id=\"pdp-graph-entrypoint-React\"]/div/div[1]')\n",
    "                    click_date.click()\n",
    "                    click_year = driver.find_element(By.XPATH, '//*[@id=\"pdp-graph-entrypoint-React\"]/div/div[2]/div/div[4]/div/div[5]')\n",
    "                    click_year.click()\n",
    "                    time.sleep(1)\n",
    "                    action = webdriver.ActionChains(driver)\n",
    "\n",
    "                    # Get the data points on the red line\n",
    "                    data_points = driver.find_elements(By.XPATH, '//*[@id=\"pdp-graph-entrypoint-React\"]/div/div[2]/div/div[3]/div[1]/div[2]/div[1]/svg/g[4]')\n",
    "                    upload_date = driver.find_element(By.XPATH, '//*[@id=\"pdp-graph-entrypoint-React\"]/div/div[2]/div/div[2]/div[1]/p[2]')\n",
    "                    \n",
    "                    #find the graph , detect red_line path \n",
    "                    line = driver.find_element(By.CLASS_NAME, 'recharts-cartesian-grid')\n",
    "                    red_line = driver.find_element(By.CSS_SELECTOR, \".recharts-layer.recharts-line\")\n",
    "                    red_line_path = red_line.find_element(By.TAG_NAME, \"path\")\n",
    "                    red_line_width = red_line_path.get_attribute(\"d\")\n",
    "\n",
    "                    \n",
    "                    values = red_line_width.split(\".\")\n",
    "                    Red_split = red_line_width.split(\"L\")\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    #get the red line number\n",
    "                    for Red_number in Red_split:\n",
    "                        if Red_number.startswith(\"M\"):\n",
    "                            Red_number_part, _ = Red_number[1:].split(\",\")\n",
    "                            Red_number_output = math.ceil(float(Red_number_part))\n",
    "                            round(Red_number_output)\n",
    "                            \n",
    "                    #move and point at graph get date       \n",
    "                    action.move_to_element(line).move_by_offset(0, 0).perform()\n",
    "                    Date_location = Red_number_output - 245\n",
    "\n",
    "                    action.move_to_element(line).move_by_offset(Date_location, 0).perform()\n",
    "\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    # small fix to get the date \n",
    "                    money_detect= driver.find_element(By.XPATH, '//*[@id=\"pdp-graph-entrypoint-React\"]/div/div[2]/div/div[2]/div[2]').text\n",
    "                    if \"-\" in money_detect  :\n",
    "                        Date_location = Date_location + 1\n",
    "                        action.move_to_element(line).move_by_offset(Date_location, 0).perform()\n",
    "\n",
    "                    upload_date = upload_date.text\n",
    "                except:\n",
    "                    upload_date = \"N/A\"\n",
    "                try:\n",
    "\n",
    "                    date_month = datetime.datetime.strptime(upload_date, '%d/%m/%Y').date()\n",
    "                    month = date_month.month\n",
    "\n",
    "                    if 3 <= month <= 5:\n",
    "                        season = \"spring\"\n",
    "                    elif 6 <= month <= 8:\n",
    "                        season = \"summer\"\n",
    "                    elif 9 <= month <= 11:\n",
    "                        season = \"autumn\"\n",
    "                    else:\n",
    "                        season = \"winter\"\n",
    "                except:\n",
    "                    season = \"N/A\"\n",
    "                try :\n",
    "                    today = datetime.date.today()\n",
    "\n",
    "                    test_date_obj = datetime.datetime.strptime(upload_date, '%d/%m/%Y').date()\n",
    "\n",
    "                    over_one_year= today - test_date_obj\n",
    "\n",
    "                    if over_one_year.days > 364:\n",
    "                        over_one_year_test = \"more_then_1_year\"   \n",
    "                    else: \n",
    "                        over_one_year_test = \"N/A\"          \n",
    "                except:\n",
    "                    over_one_year_test = \"N/A\"\n",
    "                time.sleep(1)\n",
    "                try:\n",
    "                    short_desc = \"N/A\"\n",
    "                    if driver.find_element(By.XPATH, \"//span[contains(@class, 'short-desc')]\"):\n",
    "                        span_element = driver.find_element(By.XPATH, \"//span[contains(@class, 'short-desc')]\")\n",
    "                        p_elements = span_element.find_elements(By.TAG_NAME, \"p\")\n",
    "                        p_texts = [p.text for p in p_elements]\n",
    "                        short_desc = \"\\n\".join(p_texts) \n",
    "                except:\n",
    "                    short_desc = \"N/A\"\n",
    "                    \n",
    "                try:\n",
    "                    full_desc = \"N/A\"\n",
    "                    if driver.find_element(By.XPATH, '//*[@id=\"descriptionsTab\"]/div[2]'):\n",
    "                        div_element = driver.find_element(By.XPATH, '//*[@id=\"descriptionsTab\"]/div[2]')\n",
    "                        div_elements = div_element.find_elements(By.TAG_NAME, \"div\")\n",
    "                        div_texts = [div.text for div in div_elements]\n",
    "                        full_desc = \"\\n\".join(div_texts)\n",
    "                except:\n",
    "                    full_desc = \"N/A\"\n",
    "\n",
    "                try:\n",
    "                    pattern = r\"(?:前味[：:]|初味[：:]|香調[：:]|初調[：:]|前調是|[•*]?\\s*前調[：:])(.*)\"\n",
    "                    match = re.findall(pattern, short_desc or full_desc)\n",
    "                    if match:\n",
    "                        front_note = match\n",
    "                        front_note_str = \", \".join(front_note)\n",
    "                    else:\n",
    "                        front_note_str = \"N/A\"\n",
    "                    if len(front_note_str) > 50:\n",
    "                        pattern = r\"初調[：:]|前味[：:]|前調[：:](.*)\"\n",
    "                        match = re.search(pattern, short_desc or full_desc)\n",
    "                        if match:\n",
    "                            front_note_str = match.group(1)\n",
    "                except:\n",
    "                    front_note_str = \"N/A\"\n",
    "                    \n",
    "                try :\n",
    "                    pattern_mid = r\"(?:中味[：:]|中調[：:]|中調是|[•*]?\\s*中調[：:])(.*)\"\n",
    "                    match_mid = re.findall(pattern_mid, short_desc or full_desc)\n",
    "                    if match_mid :\n",
    "                        middle_note = match_mid \n",
    "                        middle_note_str = \", \".join(middle_note)\n",
    "                    else:\n",
    "                        middle_note_str  = \"N/A\" \n",
    "                    if len(middle_note_str) > 50:\n",
    "                        pattern_mid = r\"中味[：:]|中調[：:]|中調[：:](.*)\"\n",
    "                        match_mid  = re.search(pattern_mid, short_desc or full_desc)\n",
    "                        if match_mid :\n",
    "                            middle_note_str = match_mid.group(1)\n",
    "                except:\n",
    "                    middle_note_str  = \"N/A\"    \n",
    "\n",
    "                try :\n",
    "                    pattern_base = r\"(?:後味[：:]|後味[：:]|後調[：:]|基調[：:]|後味是|後調是|[•*]?\\s*後調[：:])(.*)\"\n",
    "                    match_base = re.findall(pattern_base, short_desc or full_desc)\n",
    "                    if match_base:\n",
    "                        base_note = match_base\n",
    "                        base_note_str = \", \".join(base_note)\n",
    "                    else:\n",
    "                        base_note_str  = \"N/A\"\n",
    "                    if len(base_note_str) > 50:\n",
    "                        pattern_base = r\"中味[：:]|中調[：:]|中調[：:](.*)\"\n",
    "                        match_base = re.search(pattern_base, short_desc or full_desc)\n",
    "                        if match_base:\n",
    "                            base_note_str = match_base.group(1)\n",
    "                except:\n",
    "                    base_note_str  = \"N/A\"\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                # 將數據添加到 DataFrame\n",
    "                new_row = pd.DataFrame({\"Title\": [title],\"brand_name\":[brand_name],\"front_note\":[front_note_str],\"middle_note\":[middle_note_str],\"base_note\":[base_note_str]\n",
    "                                        , \"Price\": [price], \"Rate\": [rate], \"Origin\": [origin]\n",
    "                                        , \"upload_date\": [upload_date], \"season\": [season], \"over_one_year_test\": [over_one_year_test]})\n",
    "                data = pd.concat([data, new_row], ignore_index=True)\n",
    "\n",
    "                # 關閉新窗口並切換回主窗口\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                \n",
    "                # 更新索引以定位下一個產品\n",
    "                index += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                # 如果出現異常，說明沒有更多的產品鏈接\n",
    "                print(f\"第 {web_page_count} 頁已經處理完所有產品或出現錯誤：\", e)\n",
    "                break\n",
    "\n",
    "        # if no more page to click , BREAK\n",
    "        web_page_count = web_page_count + 1\n",
    "        print (f'{web_page_count}____________')\n",
    "        print (page_TOP_num)\n",
    "        # if get up to the max number of page , BREAK\n",
    "        if web_page_count > page_TOP_num:\n",
    "            break\n",
    "        # 重置產品索引\n",
    "        index = 1\n",
    "\n",
    "        # 嘗試找到下一頁按鈕並檢查是否可點擊\n",
    "        try:\n",
    "            nextPageButton = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@id, 'paginationMenu_nextBtn')]\")))\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            nextPageButton.click()\n",
    "            time.sleep(3)\n",
    "            print (\"Next _page _GO! \")\n",
    "            \n",
    "        except:\n",
    "            print(\"已經到達最後一頁\")\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"已經處理完所有頁面或出現錯誤：\", e)\n",
    "        break\n",
    "\n",
    "# 完成後關閉瀏覽器\n",
    "driver.quit()\n",
    "\n",
    "# 輸出 DataFrame\n",
    "print(data)\n",
    "\n",
    "#display(data) \n",
    "\n",
    "#data.to_csv('HKTVMALL_DATE_TEXT.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR Fragrance\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://fragrance.com.hk/\"\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "# Input search keyword\n",
    "input_keyword = '香水'\n",
    "search_box_compo = driver.find_element(By.XPATH, '//*[@id=\"woocommerce-product-search-field-1\"]')\n",
    "search_box_compo.send_keys(input_keyword)\n",
    "\n",
    "# Click search button\n",
    "search_button_compo = driver.find_element(By.XPATH, '//*[@id=\"site-header-inner\"]/div/section[3]/div/div[2]/div/div/div/div/form/button')\n",
    "search_button_compo.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Function to collect all product links\n",
    "def collect_product_links():\n",
    "    product_links = []\n",
    "    while True:\n",
    "        result_list = driver.find_elements(By.XPATH, \"//div[contains(@class,'product-inner clr')]\")\n",
    "        for result in result_list:\n",
    "            product_link = result.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "            product_links.append(product_link)\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, \"//a[@class='next page-numbers']\")\n",
    "            next_button.click()\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            break\n",
    "    return product_links\n",
    "\n",
    "# Collect all product links\n",
    "product_links = collect_product_links()\n",
    "\n",
    "# Initialize lists to store data\n",
    "special_offer = []\n",
    "title_list = []\n",
    "price1_list = []\n",
    "price2_list = []\n",
    "top_notes = []\n",
    "heart_notes = []\n",
    "base_notes = []\n",
    "\n",
    "# Function to scrape product details from each link\n",
    "def scrape_product_details(link):\n",
    "    driver.get(link)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        # Special offer\n",
    "        special_offer_elem = driver.find_element(By.XPATH, '//span[@class=\"onsale\"]')\n",
    "        special_offer.append(special_offer_elem.text)\n",
    "    except Exception as e:\n",
    "        special_offer.append(None)\n",
    "    \n",
    "    # Title\n",
    "    title_elem = driver.find_element(By.XPATH, '//h1[@class=\"product_title entry-title\"]')\n",
    "    title_list.append(title_elem.text)\n",
    "    \n",
    "    # Price 1\n",
    "    price1_elem = driver.find_element(By.XPATH, '//p[@class=\"price\"]//ins/span')\n",
    "    price1_list.append(price1_elem.text.replace(\"$\", \"\"))\n",
    "    \n",
    "    # Price 2 (if available)\n",
    "    try:\n",
    "        price2_elem = driver.find_element(By.XPATH, '//p[@class=\"price\"]//del/span')\n",
    "        price2_list.append(price2_elem.text.replace(\"$\", \"\"))\n",
    "    except Exception as e:\n",
    "        price2_list.append(None)\n",
    "    \n",
    "    # Fragrance notes\n",
    "    try:\n",
    "        tab_description = driver.find_element(By.XPATH, '//*[@id=\"tab-description\"]')\n",
    "        notes_text = tab_description.text\n",
    "        \n",
    "        # Extract notes\n",
    "        notes = notes_text.split('\\n')\n",
    "        top_note = None\n",
    "        heart_note = None\n",
    "        base_note = None\n",
    "        \n",
    "        for line in notes:\n",
    "            if any(marker in line for marker in ['前調: ', '前調:', '前調：', '香調：', '\"前調:', 'M前調：', '調：', '\"前調: ',\n",
    "                                                 '\"前調：', '香味: ', '香氣: ', '前調： ', '\"前調： ', '\"香味: ', '\"香味：',\n",
    "                                                 '香味：', 'Top Notes: ', '\"Middle Notes: ', '香調：木質花香調,前調：']):\n",
    "                top_note = line.split(':')[-1].strip()\n",
    "            elif any(marker in line for marker in ['中調： ', '中調：', '中調:', '中調: ', '\"中調: ', '\"Middle Notes: ', 'Middle Notes: ',\n",
    "                                                   '中調:  ', '\"heart note: ', '\"Scent: ', '\"中調：', '\"scent:', '\"Scent ',\n",
    "                                                   '\"heart note:', '\"中調： ', '\"中調:', '中調：  ']):\n",
    "                heart_note = line.split(':')[-1].strip()\n",
    "            elif any(marker in line for marker in ['基調： ', '基調：', '基調: ', '基調:', '基調:   ', '基調:  ', '\"基調：', '\"基調： ',\n",
    "                                                   '\"Base note: ', '\"基調: ', '\"Base Notes:  ', '後調：', '基調：   ', '\"基調：',\n",
    "                                                   '\"基調:', '\"Base Notes:', 'Base Notes: ', '\"後調: ','後調:']):\n",
    "                base_note = line.split(':')[-1].strip()\n",
    "        \n",
    "        top_notes.append(top_note)\n",
    "        heart_notes.append(heart_note)\n",
    "        base_notes.append(base_note)\n",
    "    except Exception as e:\n",
    "        top_notes.append(None)\n",
    "        heart_notes.append(None)\n",
    "        base_notes.append(None)\n",
    "\n",
    "# Scrape details from each product link\n",
    "for link in product_links:\n",
    "    try:\n",
    "        scrape_product_details(link)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {link}: {str(e)}\")\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "min_length = min(len(special_offer), len(title_list), len(price1_list), len(price2_list), len(top_notes), len(heart_notes), len(base_notes))\n",
    "special_offer = special_offer[:min_length]\n",
    "title_list = title_list[:min_length]\n",
    "price1_list = price1_list[:min_length]\n",
    "price2_list = price2_list[:min_length]\n",
    "top_notes = top_notes[:min_length]\n",
    "heart_notes = heart_notes[:min_length]\n",
    "base_notes = base_notes[:min_length]\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Special_offer': special_offer,\n",
    "    'Title': title_list,\n",
    "    'Price1': price1_list,\n",
    "    'Price2': price2_list,\n",
    "    'Top_notes': top_notes,\n",
    "    'Heart_notes': heart_notes,\n",
    "    'Base_notes': base_notes\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR Sasa product\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementClickInterceptedException, StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import schedule\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def initialize_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def accept_cookies(driver):\n",
    "    try:\n",
    "        iknow_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[2]/div/div[7]/a')))\n",
    "        iknow_button.click()\n",
    "    except TimeoutException:\n",
    "        print(\"未找到接受 Cookies 的按鈕\")\n",
    "\n",
    "def close_ad(driver):\n",
    "    try:\n",
    "        close_ad_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[2]/div/div[7]')))\n",
    "        close_ad_button.click()\n",
    "    except TimeoutException:\n",
    "        print(\"未找到關閉廣告的按鈕\")\n",
    "\n",
    "def navigate_to_category(driver, category_name):\n",
    "    try:\n",
    "        category_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, f'//div[text()=\"{category_name}\"]')))\n",
    "        category_button.click()\n",
    "    except TimeoutException:\n",
    "        print(f\"未找到分類為 {category_name} 的按鈕\")\n",
    "        driver.quit()\n",
    "\n",
    "def scroll_to_bottom(driver):\n",
    "    initial_result_count = len(driver.find_elements(By.XPATH, '//div[@class=\"sc-cOFCrh bNMPZm\"]'))\n",
    "    result_unchanged_count = 0\n",
    "\n",
    "    while result_unchanged_count < 10:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(EC.staleness_of(driver.find_element(By.XPATH, '//div[@class=\"sc-cOFCrh bNMPZm\"]')))\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "        \n",
    "        current_result_count = len(driver.find_elements(By.XPATH, '//div[@class=\"sc-cOFCrh bNMPZm\"]'))\n",
    "        if current_result_count == initial_result_count:\n",
    "            result_unchanged_count += 1\n",
    "        else:\n",
    "            result_unchanged_count = 0\n",
    "        initial_result_count = current_result_count\n",
    "\n",
    "def extract_product_data(driver, link):\n",
    "    # 提取產品信息\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        wait = WebDriverWait(driver, 20)  # 增加等待時間至 20 秒\n",
    "        product_name = wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'salepage-title'))).text\n",
    "        brand_name = wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'salepage-brand-list'))).text\n",
    "        \n",
    "        special_price_element = wait.until(EC.visibility_of_element_located((By.XPATH, '//span[@class=\"cms-discountMoneyColor\" and contains(text(), \"HK$\")]')))\n",
    "        special_price_text = special_price_element.text.replace(\"HK$\", \"\").strip()\n",
    "        \n",
    "        original_price_element = wait.until(EC.visibility_of_element_located((By.XPATH, '//div[@class=\"salepage-suggestprice\" and contains(text(), \"HK$\")]')))\n",
    "        original_price_text = original_price_element.text.replace(\"HK$\", \"\").strip()\n",
    "        \n",
    "        a_tags = driver.find_elements(By.XPATH, '//a[@class=\"sku-link cms-primaryBtnTextColor\"]')\n",
    "        capacity_text = a_tags[0].text.strip() if a_tags else None\n",
    "\n",
    "        # 提取成分信息\n",
    "        ingredient_section = wait.until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"salepage-detail-info\"]/div[2]')))\n",
    "        ingredients = ingredient_section.text\n",
    "\n",
    "        # 初始化前調、中調、基調\n",
    "        top_notes = None\n",
    "        heart_notes = None\n",
    "        base_notes = None\n",
    "\n",
    "        # 找到前調信息\n",
    "        top_keywords = [\"• 前調：\", \"• 前調:\", \"前調：\", \"前調:\"]\n",
    "        top_start_index = -1\n",
    "        for keyword in top_keywords:\n",
    "            if keyword in ingredients:\n",
    "                top_start_index = ingredients.find(keyword) + len(keyword)\n",
    "                break\n",
    "\n",
    "        # 找到中調信息\n",
    "        heart_keywords = [\"• 中調：\", \"• 中調:\", \"中調：\", \"中調:\"]\n",
    "        heart_start_index = -1\n",
    "        for keyword in heart_keywords:\n",
    "            if keyword in ingredients:\n",
    "                heart_start_index = ingredients.find(keyword) + len(keyword)\n",
    "                break\n",
    "\n",
    "        # 找到基調信息\n",
    "        base_keywords = [\"• 基調：\", \"• 基調:\", \"• 後調：\", \"• 後調:\", \"後調:\", \"後調：\", \"基調：\", \"基調:\"]\n",
    "        base_start_index = -1\n",
    "        for keyword in base_keywords:\n",
    "            if keyword in ingredients:\n",
    "                base_start_index = ingredients.find(keyword) + len(keyword)\n",
    "                break\n",
    "\n",
    "        # 提取前調信息\n",
    "        if top_start_index != -1:\n",
    "            next_note_index = min([i for i in [heart_start_index, base_start_index] if i != -1], default=len(ingredients))\n",
    "            top_notes = ingredients[top_start_index:next_note_index].strip().split(\"\\n\")[0]\n",
    "\n",
    "        # 提取中調信息\n",
    "        if heart_start_index != -1:\n",
    "            next_note_index = min([i for i in [base_start_index] if i != -1], default=len(ingredients))\n",
    "            heart_notes = ingredients[heart_start_index:next_note_index].strip().split(\"\\n\")[0]\n",
    "\n",
    "        # 提取基調信息\n",
    "        if base_start_index != -1:\n",
    "            base_notes = ingredients[base_start_index:].strip().split(\"\\n\")[0]\n",
    "\n",
    "        return {\n",
    "            'product_name': product_name,\n",
    "            'Original_Price': original_price_text,\n",
    "            'Special_Price': special_price_text,\n",
    "            'capacity': capacity_text,\n",
    "            'brand': brand_name,\n",
    "            'top_notes': top_notes,\n",
    "            'heart_notes': heart_notes,\n",
    "            'base_notes': base_notes\n",
    "        }\n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException, ElementClickInterceptedException, StaleElementReferenceException) as e:\n",
    "        print(e)\n",
    "        return {\n",
    "            'product_name': None,\n",
    "            'Original_Price': None,\n",
    "            'Special_Price': None,\n",
    "            'capacity': None,\n",
    "            'brand': None,\n",
    "            'top_notes': None,\n",
    "            'heart_notes': None,\n",
    "            'base_notes': None\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    try:\n",
    "        url = \"https://www.sasa.com.hk/\"\n",
    "        driver.get(url)\n",
    "        accept_cookies(driver)\n",
    "        close_ad(driver)\n",
    "        navigate_to_category(driver, \"商品分類\")\n",
    "        navigate_to_category(driver, \"香水香薰\")\n",
    "        scroll_to_bottom(driver)\n",
    "\n",
    "        product_links = []\n",
    "        result_list = driver.find_elements(By.XPATH, '//li[@class=\"column-grid-container__column\"]')\n",
    "        for result in result_list:\n",
    "            a_tag = result.find_element(By.TAG_NAME, 'a')\n",
    "            link = a_tag.get_attribute('href')\n",
    "            product_links.append(link)\n",
    "\n",
    "        extracted_data = []\n",
    "        for link in product_links:\n",
    "            data = extract_product_data(driver, link)\n",
    "            if data:\n",
    "                extracted_data.append(data)\n",
    "\n",
    "        df = pd.DataFrame(extracted_data)\n",
    "        timestamp = datetime.now().strftime('%Y%m%d')\n",
    "        filename = f'sasa_flavor_{timestamp}.csv'\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"數據提取完成，CSV 文件保存為 {filename}\")\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def run_crawler():\n",
    "    schedule.every().day.at(\"00:33\").do(main)\n",
    "\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(60)  # 每隔一分鐘檢查一次是否有任務需要運行\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_crawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sasa product comment (from 香水時代評價)\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "import difflib\n",
    "import opencc \n",
    "\n",
    "# Load CSV file\n",
    "csv_file_path = r'C:\\Users\\nat chan\\OneDrive\\桌面\\JDE10A\\Mid-Project\\clean_product_names.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Extract product names from CSV\n",
    "product_names = df['product_name'].tolist()\n",
    "\n",
    "# Initialize WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "# Uncomment the line below for headless mode\n",
    "# options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "url = \"https://www.nosetime.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Function to handle potential blocking elements\n",
    "def close_blocking_elements(driver):\n",
    "    try:\n",
    "        close_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, 'div[ng-click=\"cancel()\"]'))\n",
    "        )\n",
    "        close_button.click()\n",
    "        print(\"Blocking element closed successfully.\")\n",
    "        time.sleep(2)  # Wait for page to update\n",
    "    except TimeoutException:\n",
    "        print(\"No blocking element found or unable to click.\")\n",
    "\n",
    "sasa_product_name_list = []\n",
    "sasa_comment_rate_list = []\n",
    "number_of_raters_list = []\n",
    "\n",
    "# Initialize OpenCC for traditional to simplified Chinese conversion\n",
    "cc = opencc.OpenCC('t2s')\n",
    "\n",
    "# Iterate through all product names for search\n",
    "for index, input_text in enumerate(product_names):\n",
    "    try:\n",
    "        # Ensure input_text is a string\n",
    "        if not isinstance(input_text, str):\n",
    "            input_text = str(input_text)\n",
    "\n",
    "        # Convert traditional Chinese to simplified Chinese\n",
    "        input_text_simplified = cc.convert(input_text)\n",
    "\n",
    "        # Locate the search box and input search text\n",
    "        search_box = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'input.input'))\n",
    "        )\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(input_text_simplified)\n",
    "\n",
    "        # Click the search button\n",
    "        search_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div/div[2]/div/div[2]/form/input[1]'))\n",
    "        )\n",
    "        search_button.click()\n",
    "\n",
    "        # Handle potential blocking elements\n",
    "        close_blocking_elements(driver)\n",
    "\n",
    "        # Wait for search results to load\n",
    "        links_list = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '/html/body/div[2]/ul/div/li[1]/div/div/h2/a'))\n",
    "        )\n",
    "\n",
    "        if links_list:\n",
    "            comment_link = links_list[0].get_attribute('href')\n",
    "            driver.get(comment_link)\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Handle potential blocking elements again\n",
    "            close_blocking_elements(driver)\n",
    "\n",
    "            # Extract product name\n",
    "            sasa_product = WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, '/html/body/div[2]/ul[1]/h1'))\n",
    "            ).text.strip()\n",
    "            print(f\"Found product name: {sasa_product}\")\n",
    "\n",
    "            # Convert traditional Chinese to simplified Chinese for comparison\n",
    "            sasa_product_simplified = cc.convert(sasa_product)\n",
    "\n",
    "            # Check if found product is similar to input_text\n",
    "            similarity = difflib.SequenceMatcher(None, input_text_simplified.lower(), sasa_product_simplified.lower()).ratio()\n",
    "            if similarity > 0.5:  # Adjusted threshold to 0.5\n",
    "                # Extract rating (if available)\n",
    "                try:\n",
    "                    sasa_comment_rate_element = WebDriverWait(driver, 10).until(\n",
    "                        EC.visibility_of_element_located((By.XPATH, '//span[contains(@class, \"star\") and contains(@class, \"sa\")]'))\n",
    "                    )\n",
    "                    class_attribute = sasa_comment_rate_element.get_attribute('class')\n",
    "                    rating = int(class_attribute.split('sa')[-1]) / 2\n",
    "                    sasa_comment_rate = f\"{rating:.1f}\"\n",
    "                    print(f\"Found rating: {sasa_comment_rate}\")\n",
    "                except TimeoutException:\n",
    "                    sasa_comment_rate = None\n",
    "                    print(\"Rating not found.\")\n",
    "\n",
    "                # Extract number of raters\n",
    "                try:\n",
    "                    number_of_raters_element = WebDriverWait(driver, 10).until(\n",
    "                        EC.visibility_of_element_located((By.CLASS_NAME, 'people'))\n",
    "                    )\n",
    "                    number_of_raters = number_of_raters_element.text.replace(\" 人评分\", \"\")\n",
    "                    print(f\"Found number of raters: {number_of_raters}\")\n",
    "                except TimeoutException:\n",
    "                    print(\"Primary number of raters element not found, attempting secondary path.\")\n",
    "                    try:\n",
    "                        number_of_rater_element = WebDriverWait(driver, 10).until(\n",
    "                            EC.visibility_of_element_located((By.XPATH, '/html/body/div[2]/ul[1]/ul[2]/li/div[1]/div[2]/span[2]'))\n",
    "                        )\n",
    "                        number_of_raters = number_of_rater_element.text.replace(\" 人评分\", \"\")\n",
    "                        print(f\"Found number of raters (secondary path): {number_of_raters}\")\n",
    "                    except TimeoutException:\n",
    "                        number_of_raters = None\n",
    "                        print(\"Number of raters not found.\")\n",
    "            else:\n",
    "                print(f\"Product name mismatch: expected '{input_text}', found '{sasa_product}'\")\n",
    "                sasa_product = None\n",
    "                sasa_comment_rate = None\n",
    "                number_of_raters = None\n",
    "        else:\n",
    "            print(f\"No search results found for '{input_text}'\")\n",
    "            sasa_product = None\n",
    "            sasa_comment_rate = None\n",
    "            number_of_raters = None\n",
    "\n",
    "    except (TimeoutException, NoSuchElementException) as e:\n",
    "        print(f\"Error processing '{input_text}': {e}\")\n",
    "        sasa_product = None\n",
    "        sasa_comment_rate = None\n",
    "        number_of_raters = None\n",
    "\n",
    "    # Append results to lists\n",
    "    sasa_product_name_list.append(sasa_product)\n",
    "    sasa_comment_rate_list.append(sasa_comment_rate)\n",
    "    number_of_raters_list.append(number_of_raters)\n",
    "\n",
    "    # Return to main page\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Construct DataFrame from collected data\n",
    "df_result = pd.DataFrame({\n",
    "    'Product Name': product_names[:len(sasa_product_name_list)],\n",
    "    'Sasa Product Name': sasa_product_name_list,\n",
    "    'Comment Rate': sasa_comment_rate_list,\n",
    "    'Number of Raters': number_of_raters_list\n",
    "})\n",
    "# Display DataFrame\n",
    "display(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
